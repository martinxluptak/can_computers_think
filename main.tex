\documentclass[12pt]{olplainarticle}
% Use option lineno for line numbers 

\title{Can Computers Think?}

\author{Martin Lupták}
\keywords{artificial intelligence, social cognition, consciousness}

\begin{document}

\flushbottom
\maketitle
\thispagestyle{empty}

The question of computer sentience has puzzled scientists and philosophers alike from day one of its invention. An uninitiated reader might ask, how possibly could a mere arrangement of logical gates, a calculator, an electric toothbrush, have any decision-making capacity of its own?
Alan Turing's famous imitation game foresaw this dilemma when modern information processing speeds were yet unimaginable. If human evaluators can not distinguish the computer from humans based on its natural language responses, its ability to exhibit intelligent behavior is equivalent \cite{machinery1950computing}. Since then, the human obsession with creating living beings akin to ourselves became its area of Future Studies. Because of our brains' heightened stimulus dealing with other humans, we naturally started looking for the humane in computers. The terminology \textit{Artificial general intelligence} (AGI) was coined to describe a computer capable of accomplishing typical human tasks \cite{wang2007introduction}. When describing Artificial intelligence (AI), this article always refers to AGI.

How to prove the sentience of AGI? Namely, how can we be sure it accomplishes tasks unassisted, without deterministically taking each instruction and their exact order by a programmer? The imitation game proves lackluster in explaining this question - a system with hard-coded responses for each human response is more indistinguishable from an endless dictionary than from a human brain. If a computer's decompiled machine code gives us complete information about its every step, it can not rise beyond the sum of its parts and inhibit \emph{intelligence}, argues Searle \cite{searle1980minds}, \cite{goertzel2007artificial}. There is still a certain quality to neurobiological processes not found in cold silicon circuits. DNA-conceived beings are the only known capable of "humane" expression, leading to a notion of biological naturalism \cite{searle2002not}. However, this reasoning also condemns aliens evolved via non-neural biological processes as non-thinking.

Another point of discussion comes forth regarding creativity. Margaret Boden argues there is no special faculty or psychological property tying and discerns the factors contributing to perceived creativity in artificial intelligence \cite{boden1996creativity}. Intuitively, every work of art or scientific discovery known to man must originate from previous works in an endless causality chain. In principle, Turing completeness allows for any experimentation pattern by machines. The path towards agreement is not clear cut; in \textit{Gödel, Escher, Bach}, Douglas Hofstadter expresses his perplexion on this matter: \textit{"Sometimes it seems as though each new step towards AI, rather than producing something which everyone agrees is real intelligence, merely reveals what real intelligence is not."} \cite{hofstadter1979godel}

Perhaps the answer is tied to human relationship with computers. In the science fiction story \textit{The Lifecycle of Software Objects}, the main characters treat their AI as pets but refuse to turn them off because of their emotional attachments. One day, they are shocked to hear their AI pets' requests to allow them to work for a corporation and consent to sexual activity \cite{chiang2010lifecycle} - How blinded by safeguarding their pets they were! The story raises an uncanny question: if a computer demands citizenship or fundamental rights, are we right to ignore this plea and turn it off? Can we trust its intentions?

AI has been marked as a major source of existential risk \cite{bostrom2002existential}. An artificial intelligence whose capacity to self-improve exceeds it's human creators' might not even ask for human opinion. Perhaps it will reach a physical limit first, such as astronomical energy demands to keep functioning, rendering this speculation useless. However, in the current climate, the possibility of it becoming the new predominant lifeform on Earth is not negligible \cite{bostrom2017superintelligence}. The problem of a rogue AI capable of lying causes distress in many contemporary thinkers' minds. Such circumstances make it seem ridiculous to deny it thinking given the degree of sophistication whereas still attribute it to a three hundred neuron worm, citing determinism.

In the absence of a scientific method to measure thinking, it seems our questions' scope instead targets the complexity of a being's information processing capabilities. What about an empirical test? \textit{Is There Anything it is Like to be a Bat?} Analogically, is there an intrinsic experience to being a silicon CPU calculating the next waypoint in Tesla's new autopilot? Philosophers have come to name the subjective quality of experience qualia \cite{jackson1982epiphenomenal}. They might answer a part of our question: a computer devoid of qualia demanding citizenship is merely simulating, processing instructions of its zombie mind, whereas a computer full of them is experiencing an existentialist nightmare contemplating its shutdown. However, contemporary scholars of consciousness argue it might not be studied because experience is inherent and irreducible - from a human's mind perspective there is no method to prove, for example, that the colors in human vision are qualia-wise identical for every human, let alone for computers, or if they even exist for others at all. This is the idea behind the hard problem of consciousness \cite{chalmers1995facing}, \cite{hacker2002there}.

Nevertheless, before instigating a qualia justified computer rampage, let us reflect on the extending definition of intelligence in history - past generations of Europeans treated biologically compatible and much less neurodivergent slaves and indigenous peoples as unintelligent and did not further mourn their killing. Over time, thinking this became unacceptable on the basis of human empathy. In another extension, humanists might shed more requirements. Until we can quantify thinking more concretely, we are condemned to second-hand definitions.

Finally, consider the complex relationship humans have with computers. About three in ten Americans report being almost constantly online. Another four check the Internet multiple times a day \cite{perrin_atske_2021}. These numbers are on a steep rise from previous years \cite{smith2015us}. It is a matter of time before the inconvenience of losing connectivity outweighs the inconveniences of installing microchips inside bodies. The same goes for other aspects of our interconnected society and evolutionary process - bit by bit succumbing to intelligent design. Even if we do not acknowledge computers as thinking humans, we might soon find ourselves becoming thinking computers.


\section*{Acknowledgments}

This piece of writing was written as a part of a Masters Degree application at Technische Universität München. The text is licensed under the \href{https://creativecommons.org/licenses/by/4.0/legalcode}{Creative Commons 'Attribution' licence (CC BY)} allowing readers to distribute or build upon this work, as long as the original author is credited.

\bibliography{sample}

\end{document}